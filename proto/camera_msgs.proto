// 
// Distortion models are based on:
// [OpenCV's](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html) 
// [pinhole camera model](https://en.wikipedia.org/wiki/Distortion_%28optics%29#Software_correction)
// [ROS](http://docs.ros.org/en/diamondback/api/image_geometry/html/c++/pinhole__camera__model_8cpp_source.html)

syntax = "proto3";

package kevin;

import "standard_msgs.proto";


// A compressed image
message ImageCompressed {
  // Image format
  // 
  // Supported values: image media types supported by 
  // Chrome, such as `webp`, `jpeg`, `png`
  //
  kevin.Header heading = 1;
  bytes data = 2; // Compressed image data
  string format = 3;
}

message ImageRaw {
  // Encoding of the raw image data
  // 
  // Supported values: `8UC1`, `8UC3`, `16UC1` (little endian), 
  // `32FC1` (little endian), `bayer_bggr8`, `bayer_gbrg8`, 
  // `bayer_grbg8`, `bayer_rggb8`, `bgr8`, `bgra8`, `mono8`, 
  // `mono16`, `rgb8`, `rgba8`, `uyvy` or `yuv422`, `yuyv` 
  // or `yuv422_yuy2`
  //
  kevin.Header header = 1;
  fixed32 width = 2;
  fixed32 height = 3;
  string encoding = 4;
  fixed32 step = 5; // Byte length of a single row
  bytes data = 6;
}



message StereoRaw {
  // Encoding of the raw image data
  // 
  // Supported values: `8UC1`, `8UC3`, `16UC1` (little endian), 
  // `32FC1` (little endian), `bayer_bggr8`, `bayer_gbrg8`, 
  // `bayer_grbg8`, `bayer_rggb8`, `bgr8`, `bgra8`, `mono8`, 
  // `mono16`, `rgb8`, `rgba8`, `uyvy` or `yuv422`, `yuyv` 
  // or `yuv422_yuy2`
  //
  kevin.Header header = 1;
  fixed32 width = 2;
  fixed32 height = 3;
  string encoding = 4;
  fixed32 step = 5; // Byte length of a single row
  bytes left = 6;
  bytes right = 7;
}

// sensor_msgs/msg/CameraInfo.msg
// -----------------------------------
// std_msgs/msg/Header header
// uint32 height
// uint32 width
// string distortion_model
// double[] d
// double[9] k
// double[9] r
// double[12] p
message CameraCalibration {
  // Name of distortion model
  // 
  // Supported parameters: `plumb_bob` D = (k1, k2, p1, p2, k3)
  // and `rational_polynomial` D = (k1, k2, p1, p2, k3, k4, k5, k6).
  //
  // Intrinsic camera matrix (3x3 row-major matrix). Projects
  // 3D points in the camera coordinate frame to 2D pixel 
  // coordinates using the focal lengths (fx, fy) and
  // principal point (cx, cy).
  // 
  // ```
  //     [fx  0 cx]
  // K = [ 0 fy cy]
  //     [ 0  0  1]
  // ```
  //
  // Rectification matrix (stereo cameras only, 3x3 row-major
  // matrix). A rotation matrix aligning the camera coordinate
  // system to the ideal stereo image plane so that epipolar
  // lines in both stereo images are parallel.
  //
  // Projection/camera matrix (3x4 row-major matrix)
  // 
  // ```
  //     [fx'  0  cx' Tx]
  // P = [ 0  fy' cy' Ty]
  //     [ 0   0   1   0]
  // ```
  // 
  // By convention, this matrix specifies the intrinsic 
  // (camera) matrix of the processed (rectified) image.
  // That is, the left 3x3 portion is the normal camera
  // intrinsic matrix for the rectified image.
  // 
  // It projects 3D points in the camera coordinate
  // frame to 2D pixel coordinates using the focal
  // lengths (fx', fy') and principal point (cx', cy')
  // - these may differ from the values in K.
  // 
  // For monocular cameras, Tx = Ty = 0. Normally, 
  // monocular cameras will also have R = the identity
  // and P[1:3,1:3] = K.
  // 
  // For a stereo pair, the fourth column [Tx Ty 0]' is
  // related to the position of the optical center of the
  // second camera in the first camera's frame. We assume
  // Tz = 0 so both cameras are in the same stereo image
  // plane. The first camera always has Tx = Ty = 0. For
  // the right (second) camera of a horizontal stereo pair,
  // Ty = 0 and Tx = -fx' * B, where B is the baseline
  // between the cameras.
  // 
  // Given a 3D point [X Y Z]', the projection (x, y) of
  // the point onto the rectified image is given by:
  // 
  // ```
  // [u v w]' = P * [X Y Z 1]'
  //        x = u / w
  //        y = v / w
  // ```
  // 
  // This holds for both images of a stereo pair.
  //
  kevin.Header header = 1;
  fixed32 width = 2;
  fixed32 height = 3;
  string distortion_model = 4;
  repeated double D = 5; // length 5 or 8
  repeated double K = 6; // length 12
  repeated double R = 7; // length 9
  repeated double P = 8; // length 12
}

message DisparityImage {
  // Separate header for compatibility with current TimeSynchronizer.
  // Likely to be removed in a later release, use image.header instead.
  kevin.Header header = 1;

  // Floating point disparity image. The disparities are pre-adjusted for any
  // x-offset between the principal points of the two cameras (in the case
  // that they are verged). That is: d = x_l - x_r - (cx_l - cx_r)
  ImageRaw image = 2;

  // Stereo geometry. For disparity d, the depth from the camera is Z = fT/d.
  float f = 3; // Focal length, pixels
  float t = 4; // Baseline, world units

  // Subwindow of (potentially) valid disparity values.
  // sensor_msgs/RegionOfInterest valid_window

  // The range of disparities searched.
  // In the disparity image, any disparity less than min_disparity is invalid.
  // The disparity search range defines the horopter, or 3D volume that the
  // stereo algorithm can "see". Points with Z outside of:
  //     Z_min = fT / max_disparity
  //     Z_max = fT / min_disparity
  // could not be found.
  float min_disparity = 5;
  float max_disparity = 6;

  // Smallest allowed disparity increment. The smallest achievable depth range
  // resolution is delta_Z = (Z^2/fT)*delta_d.
  float delta_d = 7;
}
